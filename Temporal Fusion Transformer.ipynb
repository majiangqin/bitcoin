{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T03:09:14.726309Z",
     "start_time": "2024-10-14T03:09:13.431220Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_forecasting import TimeSeriesDataSet, TemporalFusionTransformer, GroupNormalizer\n",
    "from pytorch_forecasting.metrics import QuantileLoss\n",
    "import pytorch_lightning as pl\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set default tensor type to float32\n",
    "torch.set_default_tensor_type(torch.FloatTensor)\n",
    "\n",
    "# Load and preprocess data\n",
    "df = pd.read_csv('real_time_cleaned.csv')\n",
    "df['block_time'] = pd.to_datetime(df['block_time'])\n",
    "df = df.sort_values('block_time')\n",
    "\n",
    "# Feature Selection\n",
    "features = [\n",
    "    'block_height', 'tx_count', 'mempool_size_mb', 'max_fee_rate', 'avg_fee_rate',\n",
    "    'median_fee_rate', 'fee_rate_10th', 'fee_rate_90th', 'fee_rate_std',\n",
    "    'difficulty', 'hash_rate', 'mempool_min_fee', 'total_fee', 'mempool_usage',\n",
    "    'transaction_count', 'block_weight', 'block_version', 'block_interval',\n",
    "    'bitcoin_price_usd', 'hist_low_fee_ratio',\n",
    "    'hist_med_fee_ratio', 'hist_high_fee_ratio', 'hist_fee_diversity'\n",
    "]\n",
    "\n",
    "# Prepare data for TFT\n",
    "df['time_idx'] = range(len(df))\n",
    "df['group'] = 'group_0'  # Single group as a string\n",
    "\n",
    "target = 'block_median_fee_rate'\n",
    "max_encoder_length = 24  # Past 24 observations\n",
    "max_prediction_length = 10 # Predict next 10 block\n",
    "\n",
    "# Remove rows with NaN or infinite values in the target or features\n",
    "df = df.replace([np.inf, -np.inf], np.nan)\n",
    "print(\"Null values in dataset:\")\n",
    "print(df.isnull().sum())\n",
    "df = df.dropna(subset=[target] + features)\n",
    "print(f\"Shape after dropping NaNs: {df.shape}\")\n",
    "\n",
    "# Scale features and ensure float32 dtype\n",
    "scaler = StandardScaler()\n",
    "df[features] = scaler.fit_transform(df[features]).astype(np.float32)\n",
    "df[target] = df[target].astype(np.float32)\n",
    "\n",
    "# Convert 'group' to categorical\n",
    "df['group'] = df['group'].astype('category')\n",
    "\n",
    "# Create TimeSeriesDataSet with explicit configuration\n",
    "tsdataset = TimeSeriesDataSet(\n",
    "    df,\n",
    "    time_idx='time_idx',\n",
    "    target=target,\n",
    "    group_ids=['group'],\n",
    "    min_encoder_length=max_encoder_length // 2,\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    min_prediction_length=1,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    static_categoricals=['group'],\n",
    "    static_reals=[],\n",
    "    time_varying_known_reals=['time_idx'] + features,\n",
    "    time_varying_unknown_reals=[target],\n",
    "    target_normalizer=GroupNormalizer(\n",
    "        groups=['group'], transformation=\"softplus\"\n",
    "    ),\n",
    "    add_relative_time_idx=True,\n",
    "    add_target_scales=True,\n",
    "    add_encoder_length=True,\n",
    "    allow_missing_timesteps=False,\n",
    ")\n",
    "\n",
    "# Custom collate function to avoid NoneType values\n",
    "def collate_fn(batch):\n",
    "    batch = list(filter(lambda x: x is not None, batch))  # Remove NoneType items\n",
    "    return torch.utils.data.dataloader.default_collate(batch)\n",
    "\n",
    "# Create dataloaders\n",
    "batch_size = 32\n",
    "train_dataloader = DataLoader(\n",
    "    tsdataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn  # Use the custom collate function\n",
    ")\n",
    "\n",
    "# Define the Temporal Fusion Transformer model\n",
    "class BitcoinFeePredictionModel(pl.LightningModule):\n",
    "    def __init__(self, tsdataset):\n",
    "        super().__init__()\n",
    "        self.model = TemporalFusionTransformer.from_dataset(\n",
    "            tsdataset,\n",
    "            learning_rate=0.03,\n",
    "            hidden_size=32,\n",
    "            attention_head_size=2,\n",
    "            dropout=0.1,\n",
    "            hidden_continuous_size=16,\n",
    "            loss=QuantileLoss(),\n",
    "            optimizer=\"adamw\",\n",
    "            reduce_on_plateau_patience=4,\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        output = self.model(x)\n",
    "        return output\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss = self.model.training_step(batch, batch_idx)\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return self.model.configure_optimizers()\n",
    "\n",
    "# Initialize the model\n",
    "model = BitcoinFeePredictionModel(tsdataset)\n",
    "\n",
    "# Train the model\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=30,\n",
    "    accelerator='mps',  # Use MPS for Apple Silicon\n",
    "    devices=1,\n",
    ")\n",
    "\n",
    "# Debugging step to check the dataloader before fitting\n",
    "for batch_idx, batch in enumerate(train_dataloader):\n",
    "    print(f\"Batch {batch_idx} content: {batch}\")\n",
    "    if batch_idx == 0:\n",
    "        break  # Check only the first batch\n",
    "\n",
    "# Train the model\n",
    "trainer.fit(model, train_dataloader)\n",
    "\n",
    "# Prepare data for prediction\n",
    "last_data = df.iloc[-max_encoder_length:].copy()\n",
    "last_data['time_idx'] = range(last_data['time_idx'].min(), last_data['time_idx'].max() + 1)\n",
    "\n",
    "# Make predictions\n",
    "model.eval()\n",
    "predictions = model.model.predict(last_data, mode=\"raw\", return_x=True)\n",
    "\n",
    "# Extract the predicted values\n",
    "predicted_values = predictions.output.prediction.cpu().numpy()\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(12, 6))\n",
    "y_true = df[target].iloc[-max_prediction_length:].values\n",
    "plt.plot(range(len(y_true)), y_true, label='Actual')\n",
    "plt.plot(range(len(predicted_values)), predicted_values[:, 0, 0], label='Predicted')\n",
    "plt.title('Actual vs Predicted Bitcoin Fee Rates')\n",
    "plt.xlabel('Time Index')\n",
    "plt.ylabel('Fee Rate')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Calculate performance metrics\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "mae = mean_absolute_error(y_true, predicted_values[:, 0, 0])\n",
    "mse = mean_squared_error(y_true, predicted_values[:, 0, 0])\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_true, predicted_values[:, 0, 0])\n",
    "\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"Root Mean Squared Error: {rmse}\")\n",
    "print(f\"R-squared Score: {r2}\")\n"
   ],
   "id": "f097ce415d5a8b97",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values in dataset:\n",
      "block_time               0\n",
      "block_height             0\n",
      "tx_count                 0\n",
      "mempool_size_mb          0\n",
      "max_fee_rate             0\n",
      "avg_fee_rate             0\n",
      "median_fee_rate          0\n",
      "fee_rate_10th            0\n",
      "fee_rate_90th            0\n",
      "fee_rate_std             0\n",
      "difficulty               0\n",
      "hash_rate                0\n",
      "mempool_min_fee          0\n",
      "total_fee                0\n",
      "mempool_usage            0\n",
      "transaction_count        0\n",
      "block_weight             0\n",
      "block_version            0\n",
      "block_interval           0\n",
      "block_median_fee_rate    0\n",
      "mempool_fee_histogram    0\n",
      "bitcoin_price_usd        0\n",
      "hist_low_fee_ratio       0\n",
      "hist_med_fee_ratio       0\n",
      "hist_high_fee_ratio      0\n",
      "hist_fee_diversity       0\n",
      "time_idx                 0\n",
      "group                    0\n",
      "dtype: int64\n",
      "Shape after dropping NaNs: (2632, 28)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiangqinma/miniconda3/envs/bitcoin/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:208: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
      "/Users/jiangqinma/miniconda3/envs/bitcoin/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:208: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'NoneType'>",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[40], line 127\u001B[0m\n\u001B[1;32m    120\u001B[0m trainer \u001B[38;5;241m=\u001B[39m pl\u001B[38;5;241m.\u001B[39mTrainer(\n\u001B[1;32m    121\u001B[0m     max_epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m30\u001B[39m,\n\u001B[1;32m    122\u001B[0m     accelerator\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmps\u001B[39m\u001B[38;5;124m'\u001B[39m,  \u001B[38;5;66;03m# Use MPS for Apple Silicon\u001B[39;00m\n\u001B[1;32m    123\u001B[0m     devices\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[1;32m    124\u001B[0m )\n\u001B[1;32m    126\u001B[0m \u001B[38;5;66;03m# Debugging step to check the dataloader before fitting\u001B[39;00m\n\u001B[0;32m--> 127\u001B[0m \u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mbatch_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mtrain_dataloader\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m    128\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mprint\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mBatch \u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mbatch_idx\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m content: \u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mbatch\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    129\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mbatch_idx\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m:\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/bitcoin/lib/python3.11/site-packages/torch/utils/data/dataloader.py:630\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    627\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    628\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[1;32m    629\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[0;32m--> 630\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    631\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    632\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    633\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    634\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[0;32m~/miniconda3/envs/bitcoin/lib/python3.11/site-packages/torch/utils/data/dataloader.py:673\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    671\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    672\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m--> 673\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m    674\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[1;32m    675\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[0;32m~/miniconda3/envs/bitcoin/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:55\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[0;34m(self, possibly_batched_index)\u001B[0m\n\u001B[1;32m     53\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     54\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n\u001B[0;32m---> 55\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcollate_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[40], line 78\u001B[0m, in \u001B[0;36mcollate_fn\u001B[0;34m(batch)\u001B[0m\n\u001B[1;32m     76\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcollate_fn\u001B[39m(batch):\n\u001B[1;32m     77\u001B[0m     batch \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mfilter\u001B[39m(\u001B[38;5;28;01mlambda\u001B[39;00m x: x \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m, batch))  \u001B[38;5;66;03m# Remove NoneType items\u001B[39;00m\n\u001B[0;32m---> 78\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mutils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataloader\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdefault_collate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/bitcoin/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:317\u001B[0m, in \u001B[0;36mdefault_collate\u001B[0;34m(batch)\u001B[0m\n\u001B[1;32m    256\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdefault_collate\u001B[39m(batch):\n\u001B[1;32m    257\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    258\u001B[0m \u001B[38;5;124;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001B[39;00m\n\u001B[1;32m    259\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    315\u001B[0m \u001B[38;5;124;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001B[39;00m\n\u001B[1;32m    316\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 317\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcollate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcollate_fn_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdefault_collate_fn_map\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/bitcoin/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:174\u001B[0m, in \u001B[0;36mcollate\u001B[0;34m(batch, collate_fn_map)\u001B[0m\n\u001B[1;32m    171\u001B[0m transposed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39mbatch))  \u001B[38;5;66;03m# It may be accessed twice, so we use a list.\u001B[39;00m\n\u001B[1;32m    173\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(elem, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[0;32m--> 174\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m[\u001B[49m\u001B[43mcollate\u001B[49m\u001B[43m(\u001B[49m\u001B[43msamples\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcollate_fn_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcollate_fn_map\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43msamples\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtransposed\u001B[49m\u001B[43m]\u001B[49m  \u001B[38;5;66;03m# Backwards compatibility.\u001B[39;00m\n\u001B[1;32m    175\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    176\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[0;32m~/miniconda3/envs/bitcoin/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:174\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    171\u001B[0m transposed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39mbatch))  \u001B[38;5;66;03m# It may be accessed twice, so we use a list.\u001B[39;00m\n\u001B[1;32m    173\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(elem, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[0;32m--> 174\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [\u001B[43mcollate\u001B[49m\u001B[43m(\u001B[49m\u001B[43msamples\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcollate_fn_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcollate_fn_map\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m samples \u001B[38;5;129;01min\u001B[39;00m transposed]  \u001B[38;5;66;03m# Backwards compatibility.\u001B[39;00m\n\u001B[1;32m    175\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    176\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[0;32m~/miniconda3/envs/bitcoin/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:174\u001B[0m, in \u001B[0;36mcollate\u001B[0;34m(batch, collate_fn_map)\u001B[0m\n\u001B[1;32m    171\u001B[0m transposed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39mbatch))  \u001B[38;5;66;03m# It may be accessed twice, so we use a list.\u001B[39;00m\n\u001B[1;32m    173\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(elem, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[0;32m--> 174\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m[\u001B[49m\u001B[43mcollate\u001B[49m\u001B[43m(\u001B[49m\u001B[43msamples\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcollate_fn_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcollate_fn_map\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43msamples\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtransposed\u001B[49m\u001B[43m]\u001B[49m  \u001B[38;5;66;03m# Backwards compatibility.\u001B[39;00m\n\u001B[1;32m    175\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    176\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[0;32m~/miniconda3/envs/bitcoin/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:174\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    171\u001B[0m transposed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39mbatch))  \u001B[38;5;66;03m# It may be accessed twice, so we use a list.\u001B[39;00m\n\u001B[1;32m    173\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(elem, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[0;32m--> 174\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [\u001B[43mcollate\u001B[49m\u001B[43m(\u001B[49m\u001B[43msamples\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcollate_fn_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcollate_fn_map\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m samples \u001B[38;5;129;01min\u001B[39;00m transposed]  \u001B[38;5;66;03m# Backwards compatibility.\u001B[39;00m\n\u001B[1;32m    175\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    176\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[0;32m~/miniconda3/envs/bitcoin/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:192\u001B[0m, in \u001B[0;36mcollate\u001B[0;34m(batch, collate_fn_map)\u001B[0m\n\u001B[1;32m    187\u001B[0m         \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m    188\u001B[0m             \u001B[38;5;66;03m# The sequence type may not support `copy()` / `__setitem__(index, item)`\u001B[39;00m\n\u001B[1;32m    189\u001B[0m             \u001B[38;5;66;03m# or `__init__(iterable)` (e.g., `range`).\u001B[39;00m\n\u001B[1;32m    190\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m [collate(samples, collate_fn_map\u001B[38;5;241m=\u001B[39mcollate_fn_map) \u001B[38;5;28;01mfor\u001B[39;00m samples \u001B[38;5;129;01min\u001B[39;00m transposed]\n\u001B[0;32m--> 192\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(default_collate_err_msg_format\u001B[38;5;241m.\u001B[39mformat(elem_type))\n",
      "\u001B[0;31mTypeError\u001B[0m: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'NoneType'>"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c4391e14174514ea"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
