{
 "cells": [
  {
   "cell_type": "code",
   "id": "291ecc51d60a1fe6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T03:49:47.351537Z",
     "start_time": "2024-09-16T03:49:46.783118Z"
    }
   },
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "import pandas as pd\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "95f0e2374ece7a7c",
   "metadata": {},
   "source": [
    "Define Evaluation Metrics\n",
    "\n",
    "Since  predicting a continuous variable (block_median_fee_rate), regression metrics like:\n",
    "\n",
    "Mean Absolute Error (MAE)\n",
    "\n",
    "Root Mean Squared Error (RMSE)\n",
    "\n",
    "RÂ² Score"
   ]
  },
  {
   "cell_type": "code",
   "id": "b291ac857874c745",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T03:49:53.770373Z",
     "start_time": "2024-09-16T03:49:53.034588Z"
    }
   },
   "source": [
    "!pip install xgboost statsmodels tensorflow\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /Users/jiangqinma/miniconda3/envs/bitcoin/lib/python3.11/site-packages (2.1.1)\r\n",
      "Requirement already satisfied: statsmodels in /Users/jiangqinma/miniconda3/envs/bitcoin/lib/python3.11/site-packages (0.14.2)\r\n",
      "Requirement already satisfied: tensorflow in /Users/jiangqinma/miniconda3/envs/bitcoin/lib/python3.11/site-packages (2.17.0)\r\n",
      "Requirement already satisfied: numpy in /Users/jiangqinma/miniconda3/envs/bitcoin/lib/python3.11/site-packages (from xgboost) (1.26.4)\r\n",
      "Requirement already satisfied: scipy in /Users/jiangqinma/miniconda3/envs/bitcoin/lib/python3.11/site-packages (from xgboost) (1.14.1)\r\n",
      "Requirement already satisfied: pandas!=2.1.0,>=1.4 in /Users/jiangqinma/miniconda3/envs/bitcoin/lib/python3.11/site-packages (from statsmodels) (2.2.2)\r\n",
      "Requirement already satisfied: patsy>=0.5.6 in /Users/jiangqinma/miniconda3/envs/bitcoin/lib/python3.11/site-packages (from statsmodels) (0.5.6)\r\n",
      "Requirement already satisfied: packaging>=21.3 in /Users/jiangqinma/miniconda3/envs/bitcoin/lib/python3.11/site-packages (from statsmodels) (24.1)\r\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/jiangqinma/miniconda3/envs/bitcoin/lib/python3.11/site-packages (from tensorflow) (2.1.0)\r\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/jiangqinma/miniconda3/envs/bitcoin/lib/python3.11/site-packages (from tensorflow) (1.6.3)\r\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /Users/jiangqinma/miniconda3/envs/bitcoin/lib/python3.11/site-packages (from tensorflow) (24.3.25)\r\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/jiangqinma/miniconda3/envs/bitcoin/lib/python3.11/site-packages (from tensorflow) (0.6.0)\r\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/jiangqinma/miniconda3/envs/bitcoin/lib/python3.11/site-packages (from tensorflow) (0.2.0)\r\n",
      "Requirement already satisfied: h5py>=3.10.0 in /Users/jiangqinma/miniconda3/envs/bitcoin/lib/python3.11/site-packages (from tensorflow) (3.11.0)\r\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/jiangqinma/miniconda3/envs/bitcoin/lib/python3.11/site-packages (from tensorflow) (18.1.1)\r\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /Users/jiangqinma/miniconda3/envs/bitcoin/lib/python3.11/site-packages (from tensorflow) (0.4.0)\r\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/jiangqinma/miniconda3/envs/bitcoin/lib/python3.11/site-packages (from tensorflow) (3.3.0)\r\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/jiangqinma/miniconda3/envs/bitcoin/lib/python3.11/site-packages (from tensorflow) (4.25.4)\r\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/jiangqinma/miniconda3/envs/bitcoin/lib/python3.11/site-packages (from tensorflow) (2.32.3)\r\n",
      "Requirement already satisfied: setuptools in /Users/jiangqinma/miniconda3/envs/bitcoin/lib/python3.11/site-packages (from tensorflow) (72.2.0)\r\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/jiangqinma/miniconda3/envs/bitcoin/lib/python3.11/site-packages (from tensorflow) (1.16.0)\r\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/jiangqinma/miniconda3/envs/bitcoin/lib/python3.11/site-packages (from tensorflow) (2.4.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/jiangqinma/miniconda3/envs/bitcoin/lib/python3.11/site-packages (from tensorflow) (4.12.2)\r\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/jiangqinma/miniconda3/envs/bitcoin/lib/python3.11/site-packages (from tensorflow) (1.16.0)\r\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/jiangqinma/miniconda3/envs/bitcoin/lib/python3.11/site-packages (from tensorflow) (1.66.1)\r\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in /Users/jiangqinma/miniconda3/envs/bitcoin/lib/python3.11/site-packages (from tensorflow) (2.17.1)\r\n",
      "Requirement already satisfied: keras>=3.2.0 in /Users/jiangqinma/miniconda3/envs/bitcoin/lib/python3.11/site-packages (from tensorflow) (3.5.0)\r\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/jiangqinma/miniconda3/envs/bitcoin/lib/python3.11/site-packages (from tensorflow) (0.37.1)\r\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/jiangqinma/miniconda3/envs/bitcoin/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\r\n",
      "Requirement already satisfied: rich in /Users/jiangqinma/miniconda3/envs/bitcoin/lib/python3.11/site-packages (from keras>=3.2.0->tensorflow) (13.8.0)\r\n",
      "Requirement already satisfied: namex in /Users/jiangqinma/miniconda3/envs/bitcoin/lib/python3.11/site-packages (from keras>=3.2.0->tensorflow) (0.0.8)\r\n",
      "Requirement already satisfied: optree in /Users/jiangqinma/miniconda3/envs/bitcoin/lib/python3.11/site-packages (from keras>=3.2.0->tensorflow) (0.12.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/jiangqinma/miniconda3/envs/bitcoin/lib/python3.11/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2.9.0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/jiangqinma/miniconda3/envs/bitcoin/lib/python3.11/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2024.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/jiangqinma/miniconda3/envs/bitcoin/lib/python3.11/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2024.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/jiangqinma/miniconda3/envs/bitcoin/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/jiangqinma/miniconda3/envs/bitcoin/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.8)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/jiangqinma/miniconda3/envs/bitcoin/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.2)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/jiangqinma/miniconda3/envs/bitcoin/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.7.4)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/jiangqinma/miniconda3/envs/bitcoin/lib/python3.11/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/jiangqinma/miniconda3/envs/bitcoin/lib/python3.11/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\r\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/jiangqinma/miniconda3/envs/bitcoin/lib/python3.11/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.4)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/jiangqinma/miniconda3/envs/bitcoin/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/jiangqinma/miniconda3/envs/bitcoin/lib/python3.11/site-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/jiangqinma/miniconda3/envs/bitcoin/lib/python3.11/site-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/jiangqinma/miniconda3/envs/bitcoin/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\r\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "7ce9b78ff34bb335",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T03:50:00.555030Z",
     "start_time": "2024-09-16T03:49:56.689481Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "8ca23d33d0fdf178",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T03:50:10.270283Z",
     "start_time": "2024-09-16T03:50:10.102625Z"
    }
   },
   "source": [
    "df = pd.read_csv('bitcoin_data_cleaned.csv')\n",
    "df = df.set_index('block_time')\n",
    "df = df.drop(columns=['timestamp'])\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = df.drop(columns=['block_median_fee_rate'])\n",
    "y = df['block_median_fee_rate']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "ec233aca8557f1fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T03:53:25.387877Z",
     "start_time": "2024-09-16T03:52:57.105577Z"
    }
   },
   "source": [
    "# Store performance metrics for each model\n",
    "results = {}\n",
    "\n",
    "# 1. Random Forest\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_y_pred = rf_model.predict(X_test)\n",
    "results['Random Forest'] = {\n",
    "    'MAE': mean_absolute_error(y_test, rf_y_pred),\n",
    "    'RMSE': np.sqrt(mean_squared_error(y_test, rf_y_pred)),\n",
    "    'RÂ²': r2_score(y_test, rf_y_pred)\n",
    "}\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T03:53:25.394725Z",
     "start_time": "2024-09-16T03:53:25.389631Z"
    }
   },
   "cell_type": "code",
   "source": "results",
   "id": "bf1c8ba44825450b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Random Forest': {'MAE': 5.991443900256219e-08,\n",
       "  'RMSE': 1.3488465262316422e-07,\n",
       "  'RÂ²': 0.9517162245256123}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T03:53:39.489704Z",
     "start_time": "2024-09-16T03:53:39.421923Z"
    }
   },
   "cell_type": "code",
   "source": [
    "feature_importances = rf_model.feature_importances_\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# Sort feature importance values\n",
    "sorted_idx = np.argsort(feature_importances)[::-1]\n",
    "\n",
    "for idx in sorted_idx:\n",
    "    print(f\"{feature_names[idx]}: {feature_importances[idx]}\")\n"
   ],
   "id": "1b3b882c64094378",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block_height: 0.5113282096245942\n",
      "hash_rate: 0.24036485127137847\n",
      "difficulty: 0.06863439553879135\n",
      "block_interval: 0.043315673031735724\n",
      "tx_count: 0.028883753372984874\n",
      "transaction_count: 0.025152585656664197\n",
      "mempool_size_mb: 0.024923505941739393\n",
      "total_fee: 0.018950333903754227\n",
      "max_fee_rate: 0.015773619218924513\n",
      "mempool_usage: 0.011386717708480727\n",
      "block_weight: 0.005651126148097612\n",
      "block_version: 0.005374000626670254\n",
      "mempool_min_fee: 0.00025440063400363285\n",
      "fee_rate_std: 6.8273221807573654e-06\n",
      "fee_rate_90th: 0.0\n",
      "fee_rate_10th: 0.0\n",
      "median_fee_rate: 0.0\n",
      "avg_fee_rate: 0.0\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Key Observations:\n",
    "\n",
    "Most Important Features:\n",
    "\n",
    "block_height: This is the most important feature with a significant weight of 0.511.\n",
    "hash_rate: This is the second most important feature, contributing around 0.240 to the model.\n",
    "difficulty and block_interval: These also have moderate importance, suggesting that they contribute to the predictive power of the model.\n",
    "\n",
    "Less Important Features:\n",
    "\n",
    "Features like fee_rate_std, fee_rate_90th, fee_rate_10th, median_fee_rate, and avg_fee_rate have extremely low or even zero importance. This indicates that the model does not find these features useful for prediction.\n",
    "\n",
    "Mempool Features:\n",
    "\n",
    "mempool_size_mb and mempool_usage have some importance but are not very strong contributors compared to features like block_height and hash_rate.\n",
    "\n",
    "Suggested Action:\n",
    "\n",
    "Based on these observations:\n",
    "\n",
    "1. Remove Features with Very Low Importance:\n",
    " remove features like fee_rate_90th, fee_rate_10th, median_fee_rate, and avg_fee_rate, as their importance values are 0.0.\n",
    "\n",
    "Consider removing mempool_min_fee and fee_rate_std as they contribute very little to the model's performance.\n",
    "\n",
    "2. Retain Key Features:\n",
    "\n",
    "Keep the highly important features (block_height, hash_rate, difficulty, block_interval) and other moderately important ones like tx_count and mempool_size_mb.\n",
    "\n",
    "3. Rebuild the Model:\n",
    "\n",
    "Retrain the Random Forest model without the low-importance features and observe if the performance metrics (MAE, RMSE, RÂ²) improve or stay the same."
   ],
   "id": "6ecab36a7eddbb41"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T03:58:00.186982Z",
     "start_time": "2024-09-16T03:57:41.006112Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define a subset of important features based on the feature importance results\n",
    "important_features = ['block_height', 'hash_rate', 'difficulty', 'block_interval',\n",
    "                      'tx_count', 'transaction_count', 'mempool_size_mb', 'total_fee', 'max_fee_rate']\n",
    "\n",
    "# Use the important features for training the Random Forest\n",
    "X_train_imp = X_train[important_features]\n",
    "X_test_imp = X_test[important_features]\n",
    "\n",
    "# Train the model with only important features\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_imp, y_train)\n",
    "rf_y_pred = rf_model.predict(X_test_imp)\n",
    "\n",
    "# Store the performance results for the Random Forest model\n",
    "results['Random Forest (Important Features)'] = {\n",
    "    'MAE': mean_absolute_error(y_test, rf_y_pred),\n",
    "    'RMSE': np.sqrt(mean_squared_error(y_test, rf_y_pred)),\n",
    "    'RÂ²': r2_score(y_test, rf_y_pred)\n",
    "}\n"
   ],
   "id": "51884dd9265083b6",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T03:58:00.193755Z",
     "start_time": "2024-09-16T03:58:00.189944Z"
    }
   },
   "cell_type": "code",
   "source": "results",
   "id": "55349886e908e092",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Random Forest': {'MAE': 5.991443900256219e-08,\n",
       "  'RMSE': 1.3488465262316422e-07,\n",
       "  'RÂ²': 0.9517162245256123},\n",
       " 'Random Forest (Important Features)': {'MAE': 5.6041769383172356e-08,\n",
       "  'RMSE': 1.2974173105356173e-07,\n",
       "  'RÂ²': 0.9553279870653149}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T04:51:16.798437Z",
     "start_time": "2024-09-16T04:46:40.359748Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "# Define the parameter grid for tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200, 500],\n",
    "    'max_depth': [None, 10, 20, 30, 50],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2']  # Removed 'auto'\n",
    "}\n",
    "\n",
    "# Initialize RandomForestRegressor\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Initialize RandomizedSearchCV with error_score='raise' to catch any errors during search\n",
    "rf_random = RandomizedSearchCV(estimator=rf, param_distributions=param_grid,\n",
    "                               n_iter=50, cv=3, verbose=2, random_state=42, n_jobs=-1, error_score='raise')\n",
    "\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train_imp, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = rf_random.best_params_\n",
    "print(\"Best parameters found: \", best_params)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_rf_model = rf_random.best_estimator_\n",
    "rf_y_pred_best = best_rf_model.predict(X_test_imp)\n",
    "\n",
    "# Store the performance results\n",
    "results = {}\n",
    "results['Random Forest (Tuned)'] = {\n",
    "    'MAE': mean_absolute_error(y_test, rf_y_pred_best),\n",
    "    'RMSE': np.sqrt(mean_squared_error(y_test, rf_y_pred_best)),\n",
    "    'RÂ²': r2_score(y_test, rf_y_pred_best)\n",
    "}\n",
    "\n",
    "# Print the results\n",
    "print(\"Performance after tuning:\")\n",
    "for metric, value in results['Random Forest (Tuned)'].items():\n",
    "    print(f\"{metric}: {value:.6f}\")\n"
   ],
   "id": "9c2c867bf49b1575",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   3.1s\n",
      "[CV] END max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  12.8s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   6.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   8.6s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  12.1s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=  33.0s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   3.0s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   3.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   2.2s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  13.7s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   6.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=  36.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiangqinma/miniconda3/envs/bitcoin/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   3.6s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   5.0s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=  36.0s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  12.8s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   3.0s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   6.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   2.2s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  11.3s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=  32.3s\n",
      "[CV] END max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   3.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=  23.6s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   3.8s\n",
      "[CV] END max_depth=50, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   6.6s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   7.3s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   4.8s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=  35.7s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=  36.7s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  12.9s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=  31.9s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=  22.7s\n",
      "[CV] END max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   3.5s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=  23.6s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   3.8s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   6.3s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=  36.5s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   3.7s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   3.6s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   5.0s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=  37.0s\n",
      "Best parameters found:  {'n_estimators': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2', 'max_depth': None}\n",
      "Performance after tuning:\n",
      "MAE: 0.000000\n",
      "RMSE: 0.000000\n",
      "RÂ²: 0.964763\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T05:15:26.567801Z",
     "start_time": "2024-09-16T05:15:26.466969Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Scale of target variable (y_test):\")\n",
    "print(y_test.describe())\n"
   ],
   "id": "3002514461419183",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scale of target variable (y_test):\n",
      "count    9.584000e+03\n",
      "mean     4.556317e-07\n",
      "std      6.138816e-07\n",
      "min      3.013940e-08\n",
      "25%      1.280832e-07\n",
      "50%      2.400000e-07\n",
      "75%      4.775455e-07\n",
      "max      3.298996e-06\n",
      "Name: block_median_fee_rate, dtype: float64\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Our MAE and RMSE are close to zero, likely due to the small scale of the target variable, block_median_fee_rate. \n",
    " low error values are expected and appropriate for this scale.\n",
    "\n",
    "However, the block median fee rate is typically expressed in satoshis per virtual byte (sat/vB), with typical values around 2-3 sat/vB, as seen in the the website https://mempool.space/.\n",
    "\n",
    "To address this, Iâve updated the Python script (DO_real_time.py) to convert the fee rate from BTC/vB to sat/vB. We should ensure all code reflects this change and handles the new units consistently.\n",
    "\n"
   ],
   "id": "ac3fdf967ee25744"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8651220991c5c5aa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T03:50:42.450692Z",
     "start_time": "2024-09-16T03:50:42.352753Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 2. XGBoost\n",
    "xgb_model = xgb.XGBRegressor(n_estimators=100, random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "xgb_y_pred = xgb_model.predict(X_test)\n",
    "results['XGBoost'] = {\n",
    "    'MAE': mean_absolute_error(y_test, xgb_y_pred),\n",
    "    'RMSE': np.sqrt(mean_squared_error(y_test, xgb_y_pred)),\n",
    "    'RÂ²': r2_score(y_test, xgb_y_pred)\n",
    "}\n",
    "\n"
   ],
   "id": "c068d1a96bcbf41c",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T03:51:46.736907Z",
     "start_time": "2024-09-16T03:50:42.451242Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 3. LSTM Model\n",
    "def create_lstm_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=50, return_sequences=True, input_shape=input_shape))\n",
    "    model.add(LSTM(units=50))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "# Reshape data for LSTM\n",
    "X_train_lstm = X_train.values.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test_lstm = X_test.values.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "lstm_model = create_lstm_model((X_train_lstm.shape[1], 1))\n",
    "lstm_model.fit(X_train_lstm, y_train, epochs=10, batch_size=32, verbose=2)\n",
    "lstm_y_pred = lstm_model.predict(X_test_lstm)\n",
    "results['LSTM'] = {\n",
    "    'MAE': mean_absolute_error(y_test, lstm_y_pred),\n",
    "    'RMSE': np.sqrt(mean_squared_error(y_test, lstm_y_pred)),\n",
    "    'RÂ²': r2_score(y_test, lstm_y_pred)\n",
    "}\n",
    "\n"
   ],
   "id": "9361f82307a7f563",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiangqinma/miniconda3/envs/bitcoin/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1198/1198 - 8s - 6ms/step - loss: 7.7420e-05\n",
      "Epoch 2/10\n",
      "1198/1198 - 6s - 5ms/step - loss: 5.5063e-06\n",
      "Epoch 3/10\n",
      "1198/1198 - 6s - 5ms/step - loss: 4.8869e-06\n",
      "Epoch 4/10\n",
      "1198/1198 - 6s - 5ms/step - loss: 5.4228e-06\n",
      "Epoch 5/10\n",
      "1198/1198 - 6s - 5ms/step - loss: 6.0531e-06\n",
      "Epoch 6/10\n",
      "1198/1198 - 6s - 5ms/step - loss: 1.7262e-06\n",
      "Epoch 7/10\n",
      "1198/1198 - 6s - 5ms/step - loss: 2.2949e-06\n",
      "Epoch 8/10\n",
      "1198/1198 - 6s - 5ms/step - loss: 2.1165e-06\n",
      "Epoch 9/10\n",
      "1198/1198 - 6s - 5ms/step - loss: 1.5940e-06\n",
      "Epoch 10/10\n",
      "1198/1198 - 6s - 5ms/step - loss: 1.4012e-06\n",
      "\u001B[1m300/300\u001B[0m \u001B[32mââââââââââââââââââââ\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T03:51:46.741677Z",
     "start_time": "2024-09-16T03:51:46.738704Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 4. Compare results\n",
    "print(\"Model Comparison Results:\")\n",
    "for model, metrics in results.items():\n",
    "    print(f\"{model}: MAE = {metrics['MAE']}, RMSE = {metrics['RMSE']}, RÂ² = {metrics['RÂ²']}\")\n"
   ],
   "id": "90bfaa150dc4d13a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Comparison Results:\n",
      "Random Forest: MAE = 5.991443900256219e-08, RMSE = 1.3488465262316422e-07, RÂ² = 0.9517162245256123\n",
      "XGBoost: MAE = 3.881243214433048e-07, RMSE = 6.139094598098831e-07, RÂ² = -0.00019527177549383268\n",
      "LSTM: MAE = 0.000373715335135604, RMSE = 0.0003785754692153475, RÂ² = -380346.9542639499\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b334419c62f8db7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
